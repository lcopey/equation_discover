{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0615710c-e339-4a99-80be-d0d7f810cd63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-25 21:02:26.559605: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-25 21:02:26.592018: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-25 21:02:26.753527: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-25 21:02:26.753639: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-25 21:02:26.792100: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-25 21:02:26.899635: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-25 21:02:26.900926: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-25 21:02:28.013258: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from typing import Literal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GRU, Dense, Embedding, SimpleRNN, StringLookup\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from equation_discover import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccecb18f-a2de-454f-9bf2-550fdb24f22c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampler = RNNSampler(BASE_TOKENS, 16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8594385d-d0a6-4f87-b454-ab4f8935acc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(np.linspace(-2 * np.pi, 2 * np.pi), columns=[\"var_x\"])\n",
    "y = np.sin((X * 2 + 1).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629a5eb5-59f6-48a4-aef4-1bacb824ba62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressor = SymbolicRegressor(sampler, n_samples=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50116450-c454-4811-b87e-e67db7c87594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressor.compile(loss=SymbolicLoss(rsquared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8eab2fb-0d72-49fc-ba05-fe3380416407",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/laurent/miniconda3/envs/pysr_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/laurent/miniconda3/envs/pysr_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/laurent/miniconda3/envs/pysr_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/laurent/miniconda3/envs/pysr_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/laurent/miniconda3/envs/pysr_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filenu5nzrzr.py\", line 12, in tf__call\n        sequences, lengths, log_probs, entropies = ag__.converted_call(ag__.ld(self).sampler.sample, (ag__.ld(self).n_samples,), None, fscope)\n    File \"/tmp/__autograph_generated_fileir6chzus.py\", line 51, in tf__sample\n        ag__.while_stmt(loop_test, loop_body, get_state, set_state, ('entropies', 'log_probs', 'sequence_mask', 'sequences', 'counters', 'input_tensor', 'lengths'), {})\n\n    ValueError: Exception encountered when calling layer 'symbolic_regressor' (type SymbolicRegressor).\n    \n    in user code:\n    \n        File \"/home/laurent/Documents/Code/equation_discover/notebooks/../equation_discover/symbolic_regressor.py\", line 70, in call  *\n            (\n        File \"/home/laurent/Documents/Code/equation_discover/notebooks/../equation_discover/sampler.py\", line 225, in sample  *\n            while tf.reduce_any(tf.reduce_all(sequence_mask, axis=1)):\n    \n        ValueError: 'entropies' has shape (32, 0) before the loop, but shape (32, 1) after one iteration. Use tf.autograph.experimental.set_loop_options to set shape invariants.\n    \n    \n    Call arguments received by layer 'symbolic_regressor' (type SymbolicRegressor):\n      • inputs={'X': {'var_x': 'tf.Tensor(shape=(None,), dtype=float32)'}, 'y': 'tf.Tensor(shape=(None,), dtype=float32)'}\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m regressor\u001b[38;5;241m.\u001b[39mfit(X, y)\n",
      "File \u001b[0;32m~/Documents/Code/equation_discover/notebooks/../equation_discover/symbolic_regressor.py:92\u001b[0m, in \u001b[0;36mSymbolicRegressor.fit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m y \u001b[38;5;241m=\u001b[39m pandas_to_tensor(y)\n\u001b[1;32m     91\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m: x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: y}\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39minputs, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pysr_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filewzbsbl6s.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filenu5nzrzr.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m     10\u001b[0m X \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m sequences, lengths, log_probs, entropies \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39msample, (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mn_samples,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m ensemble \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(ExpressionEnsemble), (ag__\u001b[38;5;241m.\u001b[39mld(sequences), ag__\u001b[38;5;241m.\u001b[39mld(lengths)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(ensemble)\u001b[38;5;241m.\u001b[39moptimize_constants, (), \u001b[38;5;28mdict\u001b[39m(X\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(X), y\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(y)), fscope)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileir6chzus.py:51\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__sample\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m     49\u001b[0m tokens \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     50\u001b[0m parent_sibling \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparent_sibling\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m ag__\u001b[38;5;241m.\u001b[39mwhile_stmt(loop_test, loop_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropies\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_probs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence_mask\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequences\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounters\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_tensor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlengths\u001b[39m\u001b[38;5;124m'\u001b[39m), {})\n\u001b[1;32m     52\u001b[0m lengths \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_sum, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mld(sequence_mask),), \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(TF_INT_DTYPE)), fscope),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), fscope)\n\u001b[1;32m     53\u001b[0m sequence_mask_float \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mld(sequence_mask)[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],), \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(TF_FLOAT_DTYPE)), fscope)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/laurent/miniconda3/envs/pysr_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/laurent/miniconda3/envs/pysr_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/laurent/miniconda3/envs/pysr_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/laurent/miniconda3/envs/pysr_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/laurent/miniconda3/envs/pysr_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filenu5nzrzr.py\", line 12, in tf__call\n        sequences, lengths, log_probs, entropies = ag__.converted_call(ag__.ld(self).sampler.sample, (ag__.ld(self).n_samples,), None, fscope)\n    File \"/tmp/__autograph_generated_fileir6chzus.py\", line 51, in tf__sample\n        ag__.while_stmt(loop_test, loop_body, get_state, set_state, ('entropies', 'log_probs', 'sequence_mask', 'sequences', 'counters', 'input_tensor', 'lengths'), {})\n\n    ValueError: Exception encountered when calling layer 'symbolic_regressor' (type SymbolicRegressor).\n    \n    in user code:\n    \n        File \"/home/laurent/Documents/Code/equation_discover/notebooks/../equation_discover/symbolic_regressor.py\", line 70, in call  *\n            (\n        File \"/home/laurent/Documents/Code/equation_discover/notebooks/../equation_discover/sampler.py\", line 225, in sample  *\n            while tf.reduce_any(tf.reduce_all(sequence_mask, axis=1)):\n    \n        ValueError: 'entropies' has shape (32, 0) before the loop, but shape (32, 1) after one iteration. Use tf.autograph.experimental.set_loop_options to set shape invariants.\n    \n    \n    Call arguments received by layer 'symbolic_regressor' (type SymbolicRegressor):\n      • inputs={'X': {'var_x': 'tf.Tensor(shape=(None,), dtype=float32)'}, 'y': 'tf.Tensor(shape=(None,), dtype=float32)'}\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2dc80f-b29b-4da3-bb40-198fd611a8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6416e65b-12da-4d48-8486-f99d4919537e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 1/32: var_x - cos(log(var_x / var_x)) + var_x * const, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 2/32: sin(var_x * var_x * var_x + var_x * var_x + const), object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 3/32: var_x + log(log(var_x)) - var_x + var_x - var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 4/32: cos(cos(var_x)) - var_x - var_x * var_x * var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 5/32: var_x - exp(cos(exp(var_x / var_x))) - var_x * var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 6/32: sin(cos(var_x)) - exp(cos(var_x)) - var_x * var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 7/32: sin(exp(exp(exp(var_x))) + var_x + sin(exp(var_x))), object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 8/32: cos(var_x), object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 9/32: exp(sin(var_x - var_x) * var_x + var_x) - const, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 10/32: cos(log(log(var_x) / exp(var_x / var_x) * var_x)), object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 11/32: log(sin(var_x)) * var_x - var_x - var_x * var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 12/32: cos(var_x / const / var_x / var_x / const) * var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 13/32: var_x - var_x * var_x + var_x - exp(var_x * var_x), object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 14/32: exp(var_x), object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 15/32: var_x + var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:50 - Fitting 16/32: var_x * var_x - exp(const - var_x) / var_x - const, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:51 - Fitting 17/32: log(var_x - cos(var_x) - exp(var_x - const) + var_x), object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:52 - Fitting 18/32: sin(var_x) * cos(var_x) * exp(log(var_x)) * var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:52 - Fitting 19/32: var_x * sin(log(exp(var_x * var_x - var_x))) * var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:52 - Fitting 20/32: var_x / var_x + const * var_x - var_x - var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:52 - Fitting 21/32: cos(log(cos(cos(var_x / sin(var_x + var_x))) * var_x)), object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:52 - Fitting 22/32: const + const * const * var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:52 - Fitting 23/32: var_x / var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:52 - Fitting 24/32: var_x - sin(var_x - sin(cos(var_x + var_x + var_x))), object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:52 - Fitting 25/32: var_x - exp(sin(sin(var_x) + exp(var_x) - var_x)), object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:52 - Fitting 26/32: const - var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:53 - Fitting 27/32: var_x - var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:53 - Fitting 28/32: exp(exp(log(cos(var_x))) - var_x) * var_x / var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:53 - Fitting 29/32: var_x - var_x / cos(const) - var_x * var_x - var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:53 - Fitting 30/32: log(var_x) * cos(var_x) - var_x + var_x * const, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:53 - Fitting 31/32: cos(var_x) / sin(exp(log(var_x))) * var_x - var_x, object=ExpressionEnsemble\n",
      "DEBUG - 25-Dec-23 21:04:53 - Fitting 32/32: var_x * var_x * var_x + var_x + var_x - var_x, object=ExpressionEnsemble\n"
     ]
    }
   ],
   "source": [
    "output = regressor({\"X\": X, \"y\": y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204842b4-d0b6-4e1b-8606-19e89656bacb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Loss = SymbolicLoss(rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2cbe5d-89b8-4151-a4a6-dd8f6a711fda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Loss(tf.convert_to_tensor(y, dtype=tf.float32), output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae9d0c-de1f-4654-890e-44873566f029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb4a81-1500-4ff3-a6ea-73f2b104d929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba42a21c-7af8-4647-a45e-64a47395850c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65c4e898-4c42-425c-ab2d-ef8cfed4aafe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TODO constraint avoid x / x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa6e8a-4d49-449a-b48f-c059f5ea562c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import MSE\n",
    "from scipy.optimize import basinhopping, minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d32a5-510c-406e-b77d-e55f5795b145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(np.linspace(-2 * np.pi, 2 * np.pi), columns=[\"var_x\"])\n",
    "y = np.sin((X * 2 + 1).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3b4267-e668-496b-a44d-fd9488331269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expression = Expression(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baddf5ec-ef77-493f-a2be-4af94b67b2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for T in np.logspace(0, 2, 10):\n",
    "    res = basinhopping(\n",
    "        lambda constants: MSE(y, expression.eval(X, constants)),\n",
    "        expression.constants,\n",
    "        T=T,\n",
    "    )\n",
    "    results[T] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f7abbd-e900-4dcb-b5cf-e1ef3d96f817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[res.x for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa45723-bcc7-4b15-9df1-f27353140e2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = expression.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5891c0b5-ff4b-4c86-9a18-51c2b5d0f4e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expression.constants = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46125a04-fe37-4ade-91a9-6531c87e09a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "go.Figure(\n",
    "    [go.Scatter(y=expression.eval(X, res.x)), go.Scatter(y=expression.eval(X, [2, 1]))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460e47b4-1685-460d-912c-f587b0edde91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = EvalModel(tree)\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.05), loss=\"mse\")\n",
    "model.fit(\n",
    "    X,\n",
    "    y,\n",
    "    batch_size=X.shape[0],\n",
    "    epochs=1000,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"loss\", patience=10, start_from_epoch=10, min_delta=0)\n",
    "    ],\n",
    ")\n",
    "model.constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a773d9e-fe21-45ca-810f-5d22984e9fde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def step(tree, X, y, constants, optimizer: Optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = walk(tree, tf_eval, X=X, constants={\"iter\": 0, \"value\": constants})\n",
    "        loss = MSE(y, y_pred)\n",
    "    grads = tape.gradient(loss, constants)\n",
    "    optimizer.apply_gradients([(grads, constants)])\n",
    "    return grads, loss\n",
    "\n",
    "\n",
    "def optimize(\n",
    "    tree, X: pd.DataFrame, y: pd.Series, constants: tf.Variable, max_steps: int = 100\n",
    "):\n",
    "    # optimizer = SGD(learning_rate=0.1)\n",
    "    optimizer = RMSprop(learning_rate=0.1)\n",
    "\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = format_as_dict_of_tensor(X)\n",
    "\n",
    "    if isinstance(y, pd.Series):\n",
    "        y = tf.convert_to_tensor(y)\n",
    "\n",
    "    for n in range(max_steps):\n",
    "        grads, loss = step(tree, X, y, constants, optimizer)\n",
    "    return constants\n",
    "\n",
    "\n",
    "def optimize_constants(tree, X: pd.DataFrame, y: pd.Series, max_steps: int = 100):\n",
    "    num_constants = walk(tree, count_constant)\n",
    "    constants = tf.Variable(np.random.randn(num_constants), dtype=tf.float32)\n",
    "    return optimize(tree, X, y, constants, max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1523d2-1b15-4357-b3d8-54d253426556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(np.linspace(-2 * np.pi, 2 * np.pi), columns=[\"var_x\"])\n",
    "y = np.sin((X * 2 + 1).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea938a-5cb7-4adf-aec2-8189697c82f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a3a6f-8e1f-43dc-9042-f514d480a6ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xv, yv = np.meshgrid(np.linspace(-4, 4), np.linspace(-4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd0283-0b17-4d1e-8985-a7b1930a5ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losses = np.empty_like(xv)\n",
    "grads = np.empty((50, 50, 2))\n",
    "for i in range(50):\n",
    "    for j in range(50):\n",
    "        constants = tf.Variable([xv[i, j], yv[i, j]])\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = walk(tree, tf_eval, X=X, constants={\"iter\": 0, \"value\": constants})\n",
    "            loss = MSE(y, y_pred)\n",
    "        losses[i, j] = loss.numpy()\n",
    "        grad = tape.gradient(loss, constants)\n",
    "        grads[i, j] = grad.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b99aa7-bb8b-4dc2-ba3b-ba425f99dc57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "go.Figure(\n",
    "    go.Contour(x=np.linspace(-4, 4), y=np.linspace(-4, 4), z=losses, colorscale=\"RdBu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4987729-d883-46fc-b956-6e94b9e3b8d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ff.create_quiver(xv, yv, grads[:, :, 0], grads[:, :, 1], scale=0.05, arrow_scale=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b04e4d-2695-479e-8131-0e77ba7089fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af46b9-2993-4d25-9f3a-e8790430c4ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ccb260-ddf7-4368-b811-33b910574002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "constants = optimize_constants(tree, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c885c11f-4fe6-4e96-b157-95d5ae4c79ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0fc7db-e3bc-4713-994a-cdf5b5c9f9fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "go.Figure(\n",
    "    [\n",
    "        go.Scatter(\n",
    "            x=X.squeeze(),\n",
    "            y=walk(\n",
    "                tree, tf_eval, X=X, constants={\"iter\": 0, \"value\": constants}\n",
    "            ).numpy(),\n",
    "        ),\n",
    "        go.Scatter(x=X.squeeze(), y=y),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c122751-dd7c-49ce-93cf-e6288bcedcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
