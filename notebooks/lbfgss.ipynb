{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac3e9ba8-bfb9-4600-96c8-516b8fb27b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import functools\n",
    "import tensorflow as tf\n",
    "import contextlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4113867-d7fb-45ab-8275-e954c2afc4f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_val_and_grad_fn(value_fn):\n",
    "    @functools.wraps(value_fn)\n",
    "    def val_and_grad(x):\n",
    "        return tfp.math.value_and_gradient(value_fn, x)\n",
    "\n",
    "    return val_and_grad\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def timed_execution():\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    dt = time.time() - t0\n",
    "    print(\"Evaluation took: %f seconds\" % dt)\n",
    "\n",
    "\n",
    "def np_value(tensor):\n",
    "    \"\"\"Get numpy value out of possibly nested tuple of tensors.\"\"\"\n",
    "    if isinstance(tensor, tuple):\n",
    "        return type(tensor)(*(np_value(t) for t in tensor))\n",
    "    else:\n",
    "        return tensor.numpy()\n",
    "\n",
    "\n",
    "def run(optimizer):\n",
    "    \"\"\"Run an optimizer and measure it's evaluation time.\"\"\"\n",
    "    optimizer()  # Warmup.\n",
    "    with timed_execution():\n",
    "        result = optimizer()\n",
    "        return np_value(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "704f4502-297e-4751-896b-f40016cb7cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation took: 0.009760 seconds\n",
      "L-BFGS Results\n",
      "Converged: True\n",
      "Location of the minimum: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Number of iterations: 10\n"
     ]
    }
   ],
   "source": [
    "# Fix numpy seed for reproducibility\n",
    "np.random.seed(12345)\n",
    "\n",
    "# The objective must be supplied as a function that takes a single\n",
    "# (Tensor) argument and returns a tuple. The first component of the\n",
    "# tuple is the value of the objective at the supplied point and the\n",
    "# second value is the gradient at the supplied point. The value must\n",
    "# be a scalar and the gradient must have the same shape as the\n",
    "# supplied argument.\n",
    "\n",
    "# The `make_val_and_grad_fn` decorator helps transforming a function\n",
    "# returning the objective value into one that returns both the gradient\n",
    "# and the value. It also works for both eager and graph mode.\n",
    "\n",
    "dim = 10\n",
    "minimum = np.ones([dim])\n",
    "scales = np.exp(np.random.randn(dim))\n",
    "\n",
    "\n",
    "@make_val_and_grad_fn\n",
    "def quadratic(x):\n",
    "    return tf.reduce_sum(scales * (x - minimum) ** 2, axis=-1)\n",
    "\n",
    "\n",
    "# The minimization routine also requires you to supply an initial\n",
    "# starting point for the search. For this example we choose a random\n",
    "# starting point.\n",
    "start = np.random.randn(dim)\n",
    "\n",
    "# Finally an optional argument called tolerance let's you choose the\n",
    "# stopping point of the search. The tolerance specifies the maximum\n",
    "# (supremum) norm of the gradient vector at which the algorithm terminates.\n",
    "# If you don't have a specific need for higher or lower accuracy, leaving\n",
    "# this parameter unspecified (and hence using the default value of 1e-8)\n",
    "# should be good enough.\n",
    "tolerance = 1e-10\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def quadratic_with_lbfgs():\n",
    "    return tfp.optimizer.lbfgs_minimize(\n",
    "        quadratic, initial_position=tf.constant(start), tolerance=tolerance\n",
    "    )\n",
    "\n",
    "\n",
    "results = run(quadratic_with_lbfgs)\n",
    "\n",
    "# The optimization results contain multiple pieces of information. The most\n",
    "# important fields are: 'converged' and 'position'.\n",
    "# Converged is a boolean scalar tensor. As the name implies, it indicates\n",
    "# whether the norm of the gradient at the final point was within tolerance.\n",
    "# Position is the location of the minimum found. It is important to check\n",
    "# that converged is True before using the value of the position.\n",
    "\n",
    "print(\"L-BFGS Results\")\n",
    "print(\"Converged:\", results.converged)\n",
    "print(\"Location of the minimum:\", results.position)\n",
    "print(\"Number of iterations:\", results.num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ed9a3ce-2eb3-4030-8b29-eec3d180dbc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss, grads = quadratic(np.random.randn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095654b7-b493-4469-951e-2963b0abdae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
